\section {Related Work}
We divide previous works into those related to visual comparisons, color design for visualization, and visual saliency/co-saliency.
\subsection{Visual Comparison}
Visual comparison is an essential part of interactive data analysis, which is regarded as a high-level ``compound task.'' Gleicher et al.~\cite{Gleicher11} provide a systematic review of techniques developed for supporting comparisons, three basic layout designs for comparative visualization are found: \emph{juxtaposition}, \emph{superposition} and \emph{explicit encoding}. Among them, juxtaposition places different datasets in separate
% different
views without changes to the original visualization design due to its simplicity it is used in many applications~\cite{munzner2003treejuxtaposer,Albers11,Lobo15}. However, such a design often creates cognitive burden because users need to maintain a mental image of one view for comparing it with another view~\cite{LYi21}. Recently, Ondov et al.~\cite{Ondov19} and Jardine et al.~\cite{jardine2019perceptual} evaluated the perceptual effectiveness of different layouts for the comparison of bar charts with a few low-level tasks. They show that juxtaposition is less effective for tasks like finding the ``biggest delta between items''.
Accordingly, Gleicher et al.~\cite{Gleicher11} and  L'Yi et al.~\cite{LYi21} both suggested to carefully design visual encoding for improving their effectiveness. Therefore, our method facilitates visual comparison of categorical data by improving visual search using a pop-out effect~\cite{enns1990three} induced by our proposed color mapping scheme.

\subsection{Color Design}
%Creating an appropriate color mapping scheme is crucial for data visualization and has attracted considerable attention.
For a complete review of color design techniques for visualization, we refer readers to surveys such as~\cite{Tominski08,Zhou16}. We limit our discussion to techniques related to color design for categorical data visualization and specifically to the optimization of color mappings, color palette generation, and color design for multi-view visualization.

\vspace{1.5mm}
\noindent\textbf{Color Mapping Optimization}. Mapping each class to a proper color selected from a given palette is particularly helpful for categorical data visualization, since here no given order can be used. %\footnote{The word ``proper'' means that the color mapping can help user discriminate each class.}
A few %different
factors have been identified for guiding searches within such mappings.
For example, Lin et al.~\cite{lin2013selecting} proposed to optimize the compatibility between class semantics and the assigned colors. Setlur and Stone~\cite{setlur2016linguistic} produced better results by using co-occurrence measures of color name frequencies.
% For classes without clear semantics,
Kim et al.~\cite{Kim14} incorporated color aesthetics and contrast into the optimization of color assignment for image segments.
Recently, Wang et al.~\cite{Wang2018} proposed to maximize class discriminability based on color-based class separability, which takes into account spatial relationships between classes and the contrast with the background color.
Once an assignment is done, the color of each class can be further optimized to better serve different purposes, such as reducing power consumption of displays~\cite{chuang2009energy} ,
improving the accessibility of visualizations for visually impaired users~\cite{machado2009physiologically}, and better class discrimination~\cite{lee2013perceptually}.
Almost all these methods aim to generate effective visualizations for single data sets, whereas our goal is to efficiently visualize salient class differences across multiple datasets with the same label information. One example is instances of the same dataset over time.
% \ms{along similar lines as before: You often say comparing different data sets. Imho that is bit too generic as for different datasets we usually cannot assume I direct mapping between points and classes. In stead, I think of it as changing instances of the same datasets. E.g. when changing over time. Please do fix that.}

\vspace{1.5mm}
\noindent\textbf{Color Palette Generation}.
%Rather than restricting the colors provided by the selected palette, the technique of color palette generation is to select colors from the color space.
To create an appropriate categorical color palette, the commonly used approach is to select one from a library of carefully designed palettes provided by online tools (e.g. ColorBrewer~\cite{harrower2003colorbrewer}).
Colorgorical~\cite{Gramazio17} further allows users to customize color palettes by generating them based on user-specified discriminability and preference importance.
Recently, Palettailor~\cite{Lu21} takes a further step by automatically generating categorical palettes for different types of charts, such as scatterplots, line and bar charts.
However, all the aforementioned methods deal with single datasets, while our work focuses on visual comparisons within multiple
%similarly labeled
datasets with some changed instances.

\vspace{1.5mm}
\noindent\textbf{Multi-view Color Design}.
Multi-view visualizations are commonly used in multivariate analysis. Although a few design guidelines~\cite{wang2000guidelines} have been proposed for constructing multi-view visualizations, few of them are related to color design. Qu et al.~\cite{qu2017keeping} recommended a set of color consistency constraints across views.
Among them, is a high-level constraint that the same data field should always be encoded in the same way, which is related to our studied comparative visualization. Namely, all juxtaposed views should have the same color mapping scheme and a good scheme is able to help for seeing the differences between views.
However, few works have been done for finding such schemes. The only exception is comparing multiple continuous scalar fields~\cite{Tominski08} with a global color map by merging overlapping value ranges in different datasets. Our work is the first to generate appropriate color mapping for comparing multiple categorical visualizations.

\subsection{Visual Saliency \& Co-saliency}
Here we briefly review visual saliency models developed for visualizations and image co-saliency models.

\vspace{1.5mm}
\noindent\textbf{Saliency for Visualization}.
The human visual system enables viewers to concentrate on salient regions of an image while ignoring others. This is guided by two major factors~\cite{connor2004visual}: pre-attentive, bottom-up focus based on visual features (e.g., color, intensity and edges) and task-driven, top-down attention based on prior knowledge. %whereas the regions identified by these factors might be inconsistent in some cases.
Numerous saliency models~\cite{borji2019salient} have been developed to mimic the bottom-up attention mechanism in computer vision.
Most of them model image saliency as the contrast of image regions to their surroundings with low level features. Among them, the most influential one is the Itti model~\cite{Itti98}, which computes image saliency with
differences surrounding a central region.
% central surrounded differences.
Kim et al.~\cite{Kim06} tailored this model to increase the visual saliency of selected regions within a volume dataset.
%J$\ddot{a}$J
J$\ddot{a}$nicke and Chen~\cite{Janicke10} employed Itti's model~\cite{Itti98} to define a quality metric for evaluating visualizations.
Recently, Matzen et al.~\cite{Matzen18} evaluated a variety of saliency models on a large dataset and explored why these models work poorly for visualizations. One major reason is that visualizations are often created for specific goals, whereas existing models are based on  bottom-up attention. To overcome these weaknesses, they proposed a data visualization saliency (DVS) model by incorporating meaningful high-level features into Itti's model. However, this model is not designed on a class-level and cannot be directly used for categorical visualizations.
%All these models assess the quality of single images without the consideration of data analysis tasks, while our goal is to develop a model for better serving the task of visual comparison.

\vspace{1.5mm}
\noindent\textbf{Image Co-Saliency}.
Unlike single image based saliency models, the co-saliency model estimates the saliency (importance) of each pixel within the context of related images. Jacobs et al.~\cite{Jacobs10} developed a first co-saliency model for highlighting the most salient differences between two  images.  Later, this concept was extended for discovering common and salient objects/foregrounds from image collections~\cite{zhang2018review}. Inspired by the original model~\cite{Jacobs10}, our work attempts to design an appropriate color mapping for visualizing the most co-salient features among juxtaposed labeled data visualizations. Following their findings that the co-salient features can be effectively characterized by fusing image changes and single image contrast, our co-saliency model relies on two factors: class contrast in the individual views  and global features from in-between views (e.g., changes in the class structure).
