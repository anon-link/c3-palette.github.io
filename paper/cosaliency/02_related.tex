\section {Related Work}
We begin by reviewing previous work related to visual comparison, color design for visualization, and
visual saliency/co-saliency.


\subsection{Visual Comparison}
Visual comparison is an essential part of interactive data analysis, which is regarded as a high-level ``compound task.'' Gleicher et al.~\cite{Gleicher11} provide a systematic review of techniques developed for better supporting comparison and summarize three basic layout designs for comparative visualization, including \emph{juxtaposition}, \emph{superposition} and \emph{explicit encoding}. Among them, juxtaposition places different datasets in different views without any change to the original visualization design and thus it is commonly used in many applications~\cite{munzner2003treejuxtaposer,Albers11,Lobo15}. However, it often causes cognitive burden because users need to maintain a mental image of one view for comparing with another view~\cite{LYi21}. Recently, Ondov et al.~\cite{Ondov19} and Jardine et al.~\cite{jardine2019perceptual} evaluated the perceptual effectiveness of different layouts for bar charts comparison with a few low-level tasks, which show that juxtaposition is less effective in some tasks like finding ``biggest delta between items.''
Accordingly, Gleicher et al.~\cite{Gleicher11} and  L'Yi et al.~\cite{LYi21} both suggested to carefully design visual encoding for improving its effectness. Our method facilitates visual comparison of categorical data by improving the visual search with the pop-out effect~\cite{enns1990three} induced by our proposed color mapping scheme.


\subsection{Color Design}
%Creating an appropriate color mapping scheme is crucial for data visualization and has attracted considerable attention.
For a complete review of color design for visualization, we refer readers to survey papers~\cite{Tominski08,Zhou16}. We limit our discussion to the techniques related to color design for categorical data visualization including color mapping optimization, color palette generation, and color design for multi-view visualization.

\vspace{1.5mm}
\noindent\textbf{Color Mapping Optimization}. Mapping each class to a proper color selected from the given palette is particularly helpful for categorical data visualization. %\footnote{The word ``proper'' means that the color mapping can help user discriminate each class.}
A few different factors have been used for guiding the search of such mappings.
For example, Lin et al.~\cite{lin2013selecting} proposed to optimize the compatibility between the class semantics and the assigned colors. Setlur and Stone~\cite{setlur2016linguistic} produced better results by using co-occurrence measures of color name frequencies.
For the classes without clear semantics,  Hurter et al.~\cite{Hurter10} suggested to maximize perceptual color differences among close lines of a metro map.
Kim et al.~\cite{Kim14} incorporated color aesthetics and color contrast into the optimization of color assignment for image segments.
Recently, Wang et al.~\cite{Wang2018} proposed to maximize class discriminability based on color-based class separability, which takes into account spatial relationships between classes and the contrast with background color.
Once an assignment is specified, the color for each class can be further optimized to better serve different purposes, such as reducing power consumption of displays~\cite{chuang2009energy} ,
improving the accessibility of visualizations for visual impaired users~\cite{machado2009physiologically}, and better class discrimination~\cite{lee2013perceptually}.
Almost all these methods aim to generate effective visualizations for single data, whereas our goal is to efficiently visualize salient class differences across multiple similar datasets with the same label information. One example is the instances of the same datasets evolving over time.
% \ms{along similar lines as before: You often say comparing different data sets. Imho that is bit too generic as for different datasets we usually cannot assume I direct mapping between points and classes. In stead, I think of it as changing instances of the same datasets. E.g. when changing over time. Please do fix that.}

\vspace{1.5mm}
\noindent\textbf{Color Palette Generation}.
%Rather than restricting the colors provided by the selected palette, the technique of color palette generation is to select colors from the color space.
To have an appropriate categorical color palette, the commonly used approach is to select from
a library of carefully designed palettes provided by online tools (e.g. ColorBrewer~\cite{harrower2003colorbrewer}).
Colorgorical~\cite{Gramazio17} further allows users to customize color palettes by generating palettes based on user-specified discriminability and preference importance.
Chen et al.~\cite{Chen14}  suggested to directly search proper colors in CIELAB space for maximizing class discrimination in multi-class scatterplots. Yet, it cannot find enough colors with large color differences, because of leaving out L* channel in the optimization.
Recently, Palettailor~\cite{Lu21} takes a further step that can automatically generate categorical palettes for different types of charts, such as scatterplots, line and bar charts.
All the aforementioned methods deal with single data, while our work focuses on visual comparison of multiple similar labeled datasets with some changed instances.

\vspace{1.5mm}
\noindent\textbf{Multi-view Color Design}.
Multi-view visualizations are commonly used in multivariate analysis. Although a few design guidelines~\cite{wang2000guidelines} have been proposed for constructing multi-view visualizations, few of them are related to color design. Qu et al.~\cite{qu2017keeping} recommended a set of color consistency constraints across views.
Among them, the high level constraint that the same data field should be encoded in the same way is related to our studied comparative visualization. Namely, all juxtaposed views should have the same color mapping scheme and a good scheme can help for seeing the differences between views.
However, few work has been done for finding such schemes. The only exception is comparing multiple continuous scalar fields~\cite{Tominski08} with an improved global color map by merging overlapping value ranges in different datasets. Our work is the first to generate appropriate color mapping for comparing multiple categorical visualizations.



\subsection{Visual Saliency \& Co-saliency}
Here we briefly review the visual saliency model developed for visualizations and image co-saliency models.

\vspace{1.5mm}
\noindent\textbf{Saliency for Visualization}.
The human visual system enables viewers to concentrate on salient regions of an image while ignoring the others. It is guided by two major factors~\cite{connor2004visual}: pre-attentive, bottom-up attention based on visual features (e.g., color, intensity and edges) and task-driven, top-down attention based on prior knowledge. %whereas the regions identified by these factors might be inconsistent in some cases.
A numerous of saliency models~\cite{borji2019salient} have been developed to mimic bottom-up attention mechanism in computer vision community.
Most of them model image saliency as the contrast of image regions to their surroundings with low level features. Among them, the most influential one is the Itti model~\cite{Itti98}, which computes image saliency with central surrounded differences. Kim et al.~\cite{Kim06} tailored this model to increase the visual saliency of selected regions of a volume dataset.  J$\ddot{a}$nicke and Chen~\cite{Janicke10} employed this model~\cite{Itti98} to define a quality metric for evaluating visualizations.
Recently, Matzen et al.~\cite{Matzen18} evaluated a variety of saliency models on a large visualization dataset and explored why these models work poorly for visualization images. One major reason is that visualizations are often created for specific goals, whereas existing models are based on the bottom-up attention. To overcome these weaknesses, they proposed a data visualization saliency (DVS) model by incorporating meaningful high-level text features into Itti's model. However, this model is not designed on the class-level and cannot be directly used for categorical visualizations.

%All these models assess the quality of single images without the consideration of data analysis tasks, while our goal is to develop a model for better serving the task of visual comparison.


%
\vspace{1.5mm}
\noindent\textbf{Image Co-Saliency}.
Unlike single image based saliency model, the co-saliency model estimates the saliency (importance) of each pixel within the context of multiple related images. Jacobs et al.~\cite{Jacobs10} developed the first co-saliency model for highlighting the most salient differences between two compared images.  Later, this concept has been extended for discovering common and salient objects/foregrounds from image collections~\cite{zhang2018review}. Inspired by the original model~\cite{Jacobs10}, our work attempts to design an appropriate color mapping for visualizing the most co-salient features among juxtaposed labeled data visualizations. Following their findings that the co-salient features can be effectively characterized by fusing image changes and single image contrast together, our co-saliency model relies on two factors: the class contrast in individual views  and global features from in-between views (e.g., class structure changes).
