df_stat_output <- stat_table_error(data,"C3-Palette Generation")
df_stat_output <- stat_table_error(data,"C3-Palette Assignment")
ciplot(data, "error", "conditionName", "Total")
saveImg(paste(file_prefix, "error", "conditionName", "Total",sep="-"))
# Load the magic package
source('analysis.R')
# Load the magic package
source('../analysis.R')
library(forcats)
library(tidyverse)
file_study_folder <- "./data/pilot/"#"./data/"#
save_img_sign <- FALSE#TRUE#
saveImg <- function(name){
if(save_img_sign){
#ggsave(paste("results", "formal", paste(name,".pdf"), sep = "/"), width = 10, height = 6, useDingbats=FALSE)
ggsave(paste("results", "formal", paste(name,".pdf"), sep = "/"), width = 8, height = 4, useDingbats=FALSE)
}
}
# Generate the result table for error in the discrimination tasks.
stat_table_error <- function(data, compared_condition) {
print(attr)
columns <- c("Condition", "μ~95%CI", "W", "p-value", "d")
conditions <- levels(data$conditionName) %>% rev
print(conditions)
df_stats <- matrix("", ncol = length(columns), nrow = length(conditions)) %>%
data.frame() %>%
mutate_if(is.factor, as.character)
names(df_stats) <- columns
df_stats$Condition <- conditions
print(conditions)
for (index in 1:length(conditions)) {
current_condition <- conditions[index]
sub_data_one_group <- data %>% filter(conditionName==current_condition)
# 95%CI
df_stats[index, "μ~95%CI"] <- reportCI(sub_data_one_group, "error")
if(current_condition != compared_condition) {
sub_data_two_groups <- data %>% filter(conditionName==compared_condition | conditionName==current_condition)
# W test
wt <- wilcox.test(error ~ conditionName,
data = sub_data_two_groups,
conf.int=TRUE)
df_stats[index, "W"] <- as.character(wt$statistic)
df_stats[index, "p-value"] <- format(wt$p.value, format = "e", digits = 2)
# alternative report: with breaks.
# if(wt$p.value < 0.05) { df_stats[index, "p-value"] <- "< 0.05"}
# if(wt$p.value < 0.01) { df_stats[index, "p-value"] <- "< 0.01"}
# if(wt$p.value < 0.001) { df_stats[index, "p-value"] <- "< 0.001"}
# else { df_stats[index, "p-value"] <- "≥ 0.05" }
# Effect size
df_stats[index, "d"] <- reportES(sub_data_two_groups, "error", "conditionName")
}
}
print(df_stats)
return(df_stats)
}
# Generate the result table for time in the discrimination tasks.
stat_table_time <- function(data, compared_condition) {
print(attr)
columns <- c("Condition", "μ~95%CI", "W", "p-value", "d")
conditions <- levels(data$conditionName) %>% rev
print(conditions)
df_stats <- matrix("", ncol = length(columns), nrow = length(conditions)) %>%
data.frame() %>%
mutate_if(is.factor, as.character)
names(df_stats) <- columns
df_stats$Condition <- conditions
print(conditions)
for (index in 1:length(conditions)) {
current_condition <- conditions[index]
sub_data_one_group <- data %>% filter(conditionName==current_condition)
# 95%CI
df_stats[index, "μ~95%CI"] <- reportCI(sub_data_one_group, "totalTime")
if(current_condition != compared_condition) {
sub_data_two_groups <- data %>% filter(conditionName==compared_condition | conditionName==current_condition)
# W test
wt <- wilcox.test(totalTime ~ conditionName,
data = sub_data_two_groups,
conf.int=TRUE)
df_stats[index, "W"] <- as.character(wt$statistic)
df_stats[index, "p-value"] <- format(wt$p.value, format = "e", digits = 2)
# alternative report: with breaks.
# if(wt$p.value < 0.05) { df_stats[index, "p-value"] <- "< 0.05"}
# if(wt$p.value < 0.01) { df_stats[index, "p-value"] <- "< 0.01"}
# if(wt$p.value < 0.001) { df_stats[index, "p-value"] <- "< 0.001"}
# else { df_stats[index, "p-value"] <- "≥ 0.05" }
# Effect size
df_stats[index, "d"] <- reportES(sub_data_two_groups, "totalTime", "conditionName")
}
}
print(df_stats)
return(df_stats)
}
# Get the list of files.
file_path <- paste(file_study_folder, "co-saliency", '', sep = "/")#
filelist <- list.files(path = file_path, pattern = '*coSaliency.*?\\.csv$')
# Compute data_total
data_total <- rbind()
total_time <- c()
for (file in filelist) {
print(file)
# read data
data_temp <- read.csv(paste(file_path, file, sep = ""), header = TRUE) %>%
# Remove duplicated rows with extremely long time
filter(totalTime < 1000)
# Remove another type of duplicated rows, if any
test <- data_temp %>%
group_by(userName, fileId, conditionId, changeMagnitude, changeType) %>%
summarise(count = n())
if(nrow(test) != nrow(data_temp)) {
# Print the dataframe if there're duplicated rows.
#print(data_temp)
#print(test)
data_temp <- data_temp %>%
group_by(userName, fileId, conditionId, changeMagnitude, changeType) %>%
slice(c(n())) %>%
ungroup()
}
xx <- strsplit(file, "-")
group_id <- xx[[1]][1]
data_temp <- data_temp %>%
mutate(errorTime=ifelse(userResult!=1, totalTime, 0)) %>%
mutate(accuracy=userResult) %>%
mutate(datasetGroup = rep(as.numeric(group_id),times=nrow(data_temp)))
for(i in 1:nrow(data_temp)){
user_result <- as.numeric(unlist(strsplit(as.vector(data_temp[i,]$clickOrder), "-")))
right_result <- as.numeric(unlist(strsplit(as.vector(data_temp[i,]$rightAnswer), "-")))
intersect_elements <- intersect(user_result, right_result)
#print(right_result)
#print(intersect_elements)
#print(length(intersect_elements))
data_temp[i,]$accuracy <- length(intersect_elements)/length(right_result)
#print(data_temp[i,]$accuracy)
}
# sum the time of each user
total_time <- c(total_time, sum(data_temp$totalTime))
# bind the data to the total data frame
data_total <- rbind(data_total, data_temp)
# check each data: error rate of each condition
group_data <- dplyr::summarise(group_by(data_temp,conditionId, userResult),count=n(), time=sum(totalTime))
group_data_total <- dplyr::summarise(group_by(data_temp,conditionId),count=n(), time=sum(totalTime))
for(i in 1:nrow(group_data_total)){
x <- group_data_total[i,]
x1 <- group_data[group_data$conditionId==x["conditionId"][[1]] & group_data$userResult==0,]
if(nrow(x1)==0){
cat(toString(x["conditionId"][[1]]), " error rate is ", 0, ", time is ",x["time"][[1]],"\n")
}else{
cat(toString(x["conditionId"][[1]]), " error rate is ", x1["count"][[1]]/x["count"][[1]], ", time is ",x1["time"][[1]],"\n")
}
}
data_t <- data_temp[data_temp$conditionId==-1 & data_temp$userResult==0, ]
cat("distractor trials error rate is ", nrow(data_t)/4,"\n")
if(nrow(data_t)/4>0){
print("=============================")
}
data_t <- data_temp[data_temp$totalTime==60, ]
if(nrow(data_t)/nrow(data_temp)>0){
cat("totalTime==60 rate is ", nrow(data_t)/nrow(data_temp),"\n")
print("=============================")
}
if(nrow(data_temp)!=40){
print(nrow(data_temp))
print("*********************************")
}
}
#write.csv(data_total, paste(file_path, "statics.csv", sep = ""))
cat("\n", "average time is ", toString(mean(total_time)/60), "min\n")
mean_time <- (sum(total_time)-max(total_time)-min(total_time))/(length(total_time)-2)
cat("average time (remove max and min) is ", toString(mean_time/60), "min\n")
cat("max time is ", toString(max(total_time)/60), "min\n")
cat("min time is ", toString(min(total_time)/60), "min\n")
# Uncomment if want to check the trial numbers per participant.
# temp <- data_total %>%
#   group_by(userName) %>%
#   summarise(trials = n()) %>%
#   filter(trials != 30)
# Compute variables like error
data_total <- data_total %>%
mutate(error=ifelse(userResult!=0, 0, 1)) %>%
mutate(datasetId=fileId)
# Load the magic package
source('../analysis.R')
library(forcats)
library(tidyverse)
file_study_folder <- "../data/pilot/"#"./data/"#
save_img_sign <- FALSE#TRUE#
saveImg <- function(name){
if(save_img_sign){
#ggsave(paste("results", "formal", paste(name,".pdf"), sep = "/"), width = 10, height = 6, useDingbats=FALSE)
ggsave(paste("results", "formal", paste(name,".pdf"), sep = "/"), width = 8, height = 4, useDingbats=FALSE)
}
}
# Generate the result table for error in the discrimination tasks.
stat_table_error <- function(data, compared_condition) {
print(attr)
columns <- c("Condition", "μ~95%CI", "W", "p-value", "d")
conditions <- levels(data$conditionName) %>% rev
print(conditions)
df_stats <- matrix("", ncol = length(columns), nrow = length(conditions)) %>%
data.frame() %>%
mutate_if(is.factor, as.character)
names(df_stats) <- columns
df_stats$Condition <- conditions
print(conditions)
for (index in 1:length(conditions)) {
current_condition <- conditions[index]
sub_data_one_group <- data %>% filter(conditionName==current_condition)
# 95%CI
df_stats[index, "μ~95%CI"] <- reportCI(sub_data_one_group, "error")
if(current_condition != compared_condition) {
sub_data_two_groups <- data %>% filter(conditionName==compared_condition | conditionName==current_condition)
# W test
wt <- wilcox.test(error ~ conditionName,
data = sub_data_two_groups,
conf.int=TRUE)
df_stats[index, "W"] <- as.character(wt$statistic)
df_stats[index, "p-value"] <- format(wt$p.value, format = "e", digits = 2)
# alternative report: with breaks.
# if(wt$p.value < 0.05) { df_stats[index, "p-value"] <- "< 0.05"}
# if(wt$p.value < 0.01) { df_stats[index, "p-value"] <- "< 0.01"}
# if(wt$p.value < 0.001) { df_stats[index, "p-value"] <- "< 0.001"}
# else { df_stats[index, "p-value"] <- "≥ 0.05" }
# Effect size
df_stats[index, "d"] <- reportES(sub_data_two_groups, "error", "conditionName")
}
}
print(df_stats)
return(df_stats)
}
# Generate the result table for time in the discrimination tasks.
stat_table_time <- function(data, compared_condition) {
print(attr)
columns <- c("Condition", "μ~95%CI", "W", "p-value", "d")
conditions <- levels(data$conditionName) %>% rev
print(conditions)
df_stats <- matrix("", ncol = length(columns), nrow = length(conditions)) %>%
data.frame() %>%
mutate_if(is.factor, as.character)
names(df_stats) <- columns
df_stats$Condition <- conditions
print(conditions)
for (index in 1:length(conditions)) {
current_condition <- conditions[index]
sub_data_one_group <- data %>% filter(conditionName==current_condition)
# 95%CI
df_stats[index, "μ~95%CI"] <- reportCI(sub_data_one_group, "totalTime")
if(current_condition != compared_condition) {
sub_data_two_groups <- data %>% filter(conditionName==compared_condition | conditionName==current_condition)
# W test
wt <- wilcox.test(totalTime ~ conditionName,
data = sub_data_two_groups,
conf.int=TRUE)
df_stats[index, "W"] <- as.character(wt$statistic)
df_stats[index, "p-value"] <- format(wt$p.value, format = "e", digits = 2)
# alternative report: with breaks.
# if(wt$p.value < 0.05) { df_stats[index, "p-value"] <- "< 0.05"}
# if(wt$p.value < 0.01) { df_stats[index, "p-value"] <- "< 0.01"}
# if(wt$p.value < 0.001) { df_stats[index, "p-value"] <- "< 0.001"}
# else { df_stats[index, "p-value"] <- "≥ 0.05" }
# Effect size
df_stats[index, "d"] <- reportES(sub_data_two_groups, "totalTime", "conditionName")
}
}
print(df_stats)
return(df_stats)
}
# Get the list of files.
file_path <- paste(file_study_folder, "co-saliency", '', sep = "/")#
filelist <- list.files(path = file_path, pattern = '*coSaliency.*?\\.csv$')
# Compute data_total
data_total <- rbind()
total_time <- c()
for (file in filelist) {
print(file)
# read data
data_temp <- read.csv(paste(file_path, file, sep = ""), header = TRUE) %>%
# Remove duplicated rows with extremely long time
filter(totalTime < 1000)
# Remove another type of duplicated rows, if any
test <- data_temp %>%
group_by(userName, fileId, conditionId, changeMagnitude, changeType) %>%
summarise(count = n())
if(nrow(test) != nrow(data_temp)) {
# Print the dataframe if there're duplicated rows.
#print(data_temp)
#print(test)
data_temp <- data_temp %>%
group_by(userName, fileId, conditionId, changeMagnitude, changeType) %>%
slice(c(n())) %>%
ungroup()
}
xx <- strsplit(file, "-")
group_id <- xx[[1]][1]
data_temp <- data_temp %>%
mutate(errorTime=ifelse(userResult!=1, totalTime, 0)) %>%
mutate(accuracy=userResult) %>%
mutate(datasetGroup = rep(as.numeric(group_id),times=nrow(data_temp)))
for(i in 1:nrow(data_temp)){
user_result <- as.numeric(unlist(strsplit(as.vector(data_temp[i,]$clickOrder), "-")))
right_result <- as.numeric(unlist(strsplit(as.vector(data_temp[i,]$rightAnswer), "-")))
intersect_elements <- intersect(user_result, right_result)
#print(right_result)
#print(intersect_elements)
#print(length(intersect_elements))
data_temp[i,]$accuracy <- length(intersect_elements)/length(right_result)
#print(data_temp[i,]$accuracy)
}
# sum the time of each user
total_time <- c(total_time, sum(data_temp$totalTime))
# bind the data to the total data frame
data_total <- rbind(data_total, data_temp)
# check each data: error rate of each condition
group_data <- dplyr::summarise(group_by(data_temp,conditionId, userResult),count=n(), time=sum(totalTime))
group_data_total <- dplyr::summarise(group_by(data_temp,conditionId),count=n(), time=sum(totalTime))
for(i in 1:nrow(group_data_total)){
x <- group_data_total[i,]
x1 <- group_data[group_data$conditionId==x["conditionId"][[1]] & group_data$userResult==0,]
if(nrow(x1)==0){
cat(toString(x["conditionId"][[1]]), " error rate is ", 0, ", time is ",x["time"][[1]],"\n")
}else{
cat(toString(x["conditionId"][[1]]), " error rate is ", x1["count"][[1]]/x["count"][[1]], ", time is ",x1["time"][[1]],"\n")
}
}
data_t <- data_temp[data_temp$conditionId==-1 & data_temp$userResult==0, ]
cat("distractor trials error rate is ", nrow(data_t)/4,"\n")
if(nrow(data_t)/4>0){
print("=============================")
}
data_t <- data_temp[data_temp$totalTime==60, ]
if(nrow(data_t)/nrow(data_temp)>0){
cat("totalTime==60 rate is ", nrow(data_t)/nrow(data_temp),"\n")
print("=============================")
}
if(nrow(data_temp)!=40){
print(nrow(data_temp))
print("*********************************")
}
}
#write.csv(data_total, paste(file_path, "statics.csv", sep = ""))
cat("\n", "average time is ", toString(mean(total_time)/60), "min\n")
mean_time <- (sum(total_time)-max(total_time)-min(total_time))/(length(total_time)-2)
cat("average time (remove max and min) is ", toString(mean_time/60), "min\n")
cat("max time is ", toString(max(total_time)/60), "min\n")
cat("min time is ", toString(min(total_time)/60), "min\n")
# Uncomment if want to check the trial numbers per participant.
# temp <- data_total %>%
#   group_by(userName) %>%
#   summarise(trials = n()) %>%
#   filter(trials != 30)
# Compute variables like error
data_total <- data_total %>%
mutate(error=ifelse(userResult!=0, 0, 1)) %>%
mutate(datasetId=fileId)
# removing the distractors
data_total <- data_total[data_total$conditionId!=-1, ]
# Prep Plot Consistency
data_total <- data_total %>%
mutate(conditionName = conditionId) %>%
mutate(conditionMagnitude = conditionId)
data_total[data_total$conditionId==0, ]$conditionName <- "Random Assignment"
data_total[data_total$conditionId==1, ]$conditionName <- "Optimized Assignment"
data_total[data_total$conditionId==2, ]$conditionName <- "Alpha Blending"
data_total[data_total$conditionId==3, ]$conditionName <- "C3-Palette Assignment"
data_total[data_total$conditionId==4, ]$conditionName <- "Palettailor"
data_total[data_total$conditionId==5, ]$conditionName <- "C3-Palette Generation"
data_total <- data_total %>%
mutate(conditionName = fct_relevel(conditionName,
"C3-Palette Generation",
"Palettailor", "C3-Palette Assignment",
"Alpha Blending", "Optimized Assignment", "Random Assignment"))
condition_names <- c("Random Assignment", "Optimized Assignment", "Alpha Blending", "C3-Palette Assignment", "Palettailor", "C3-Palette Generation")
# 0 is small, 1 is medium, 2 is large
for(i in 1:6){
for(j in 0:2){
data_total[data_total$conditionId==(i-1) & data_total$changeMagnitude==j, ]$conditionMagnitude <- paste(condition_names[i], j, sep = "-")
}
}
# check which data of Ours generation is wrong
ours_data_error <- data_total[data_total$conditionId==5 & data_total$userResult==0, ]
# compute the time threshold
data_time_correct <- data_total[data_total$userResult==1, ]
data_time_threshold_correct <- data_total[data_total$totalTime<=30 & data_total$userResult==1, ]
threshold <- nrow(data_time_threshold_correct)/nrow(data_time_correct)
cat("time threshold is ", threshold, "\n")
print(data_total)
# Get the list of files.
file_path <- paste(file_study_folder, "co-saliency", '', sep = "/")#
filelist <- list.files(path = file_path, pattern = '*coSaliency.*?\\.csv$')
# Compute data_total
data_total <- rbind()
total_time <- c()
for (file in filelist) {
print(file)
# read data
data_temp <- read.csv(paste(file_path, file, sep = ""), header = TRUE) %>%
# Remove duplicated rows with extremely long time
filter(totalTime < 1000)
# Remove another type of duplicated rows, if any
test <- data_temp %>%
group_by(userName, fileId, conditionId, changeMagnitude, changeType) %>%
summarise(count = n())
if(nrow(test) != nrow(data_temp)) {
# Print the dataframe if there're duplicated rows.
#print(data_temp)
#print(test)
data_temp <- data_temp %>%
group_by(userName, fileId, conditionId, changeMagnitude, changeType) %>%
slice(c(n())) %>%
ungroup()
}
xx <- strsplit(file, "-")
group_id <- xx[[1]][1]
data_temp <- data_temp %>%
mutate(errorTime=ifelse(userResult!=1, totalTime, 0)) %>%
mutate(accuracy=userResult) %>%
mutate(datasetGroup = rep(as.numeric(group_id),times=nrow(data_temp)))
for(i in 1:nrow(data_temp)){
user_result <- as.numeric(unlist(strsplit(as.vector(data_temp[i,]$clickOrder), "-")))
right_result <- as.numeric(unlist(strsplit(as.vector(data_temp[i,]$rightAnswer), "-")))
intersect_elements <- intersect(user_result, right_result)
#print(right_result)
#print(intersect_elements)
#print(length(intersect_elements))
data_temp[i,]$accuracy <- length(intersect_elements)/length(right_result)
#print(data_temp[i,]$accuracy)
}
# sum the time of each user
total_time <- c(total_time, sum(data_temp$totalTime))
# bind the data to the total data frame
data_total <- rbind(data_total, data_temp)
# check each data: error rate of each condition
group_data <- dplyr::summarise(group_by(data_temp,conditionId, userResult),count=n(), time=sum(totalTime))
group_data_total <- dplyr::summarise(group_by(data_temp,conditionId),count=n(), time=sum(totalTime))
for(i in 1:nrow(group_data_total)){
x <- group_data_total[i,]
x1 <- group_data[group_data$conditionId==x["conditionId"][[1]] & group_data$userResult==0,]
if(nrow(x1)==0){
cat(toString(x["conditionId"][[1]]), " error rate is ", 0, ", time is ",x["time"][[1]],"\n")
}else{
cat(toString(x["conditionId"][[1]]), " error rate is ", x1["count"][[1]]/x["count"][[1]], ", time is ",x1["time"][[1]],"\n")
}
}
data_t <- data_temp[data_temp$conditionId==-1 & data_temp$userResult==0, ]
cat("distractor trials error rate is ", nrow(data_t)/4,"\n")
if(nrow(data_t)/4>0){
print("=============================")
}
data_t <- data_temp[data_temp$totalTime==60, ]
if(nrow(data_t)/nrow(data_temp)>0){
cat("totalTime==60 rate is ", nrow(data_t)/nrow(data_temp),"\n")
print("=============================")
}
if(nrow(data_temp)!=40){
print(nrow(data_temp))
print("*********************************")
}
}
#write.csv(data_total, paste(file_path, "statics.csv", sep = ""))
cat("\n", "average time is ", toString(mean(total_time)/60), "min\n")
mean_time <- (sum(total_time)-max(total_time)-min(total_time))/(length(total_time)-2)
cat("average time (remove max and min) is ", toString(mean_time/60), "min\n")
cat("max time is ", toString(max(total_time)/60), "min\n")
cat("min time is ", toString(min(total_time)/60), "min\n")
# Uncomment if want to check the trial numbers per participant.
# temp <- data_total %>%
#   group_by(userName) %>%
#   summarise(trials = n()) %>%
#   filter(trials != 30)
# Compute variables like error
data_total <- data_total %>%
mutate(error=ifelse(userResult!=0, 0, 1)) %>%
mutate(datasetId=fileId)
# removing the distractors
data_total <- data_total[data_total$conditionId!=-1, ]
# Prep Plot Consistency
data_total <- data_total %>%
mutate(conditionName = conditionId) %>%
mutate(conditionMagnitude = conditionId)
data_total[data_total$conditionId==0, ]$conditionName <- "Random Assignment"
data_total[data_total$conditionId==1, ]$conditionName <- "Optimized Assignment"
data_total[data_total$conditionId==2, ]$conditionName <- "Alpha Blending"
data_total[data_total$conditionId==3, ]$conditionName <- "C3-Palette Assignment"
data_total[data_total$conditionId==4, ]$conditionName <- "Palettailor"
data_total[data_total$conditionId==5, ]$conditionName <- "C3-Palette Generation"
data_total <- data_total %>%
mutate(conditionName = fct_relevel(conditionName,
"C3-Palette Generation",
"Palettailor", "C3-Palette Assignment",
"Alpha Blending", "Optimized Assignment", "Random Assignment"))
condition_names <- c("Random Assignment", "Optimized Assignment", "Alpha Blending", "C3-Palette Assignment", "Palettailor", "C3-Palette Generation")
# 0 is small, 1 is medium, 2 is large
for(i in 1:6){
for(j in 0:2){
data_total[data_total$conditionId==(i-1) & data_total$changeMagnitude==j, ]$conditionMagnitude <- paste(condition_names[i], j, sep = "-")
}
}
# check which data of Ours generation is wrong
ours_data_error <- data_total[data_total$conditionId==5 & data_total$userResult==0, ]
# compute the time threshold
data_time_correct <- data_total[data_total$userResult==1, ]
data_time_threshold_correct <- data_total[data_total$totalTime<=30 & data_total$userResult==1, ]
threshold <- nrow(data_time_threshold_correct)/nrow(data_time_correct)
cat("time threshold is ", threshold, "\n")
print(data_total)
print(nrow(data_total[data_total$totalTime<60, ])/nrow(data_total))
# mean value
data <- dplyr::summarise(group_by(data_part, userName, conditionName), error=mean(titer))
#Statistical Test Results: mu~95% CI, W, p-value, d.
# error~conditionName and time~conditionName
df_stat_output <- stat_table_error(data,"C3-Palette Generation")
df_stat_output <- stat_table_error(data,"C3-Palette Assignment")
ciplot(data, "error", "conditionName", "Part-mean")
saveImg(paste(file_prefix, "error", "conditionName", "Part-mean",sep="-"))
